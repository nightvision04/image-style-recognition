{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import connections as con\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def json_loads(a):\n",
    "    return np.array(json.loads(a))\n",
    "    \n",
    "class X_data:\n",
    "    ''' This object will contain the models active from the database\n",
    "        active_dfs = Active_dfs()\n",
    "        # Creates: Active_dfs().df_dict[pair] for each active pair\n",
    "    '''\n",
    "    def __init__(self,connection,table):\n",
    "        ''' This is run whenever the object is first created\n",
    "        '''\n",
    "        \n",
    "        self.df =  con.get_id_strips(connection,table)\n",
    "        self.df['x'] = self.df.apply(lambda row: json_loads(row['x']), axis=1)\n",
    "        self.df['tags'] = self.df.apply(lambda row: json_loads(row['tags']), axis=1)\n",
    "        print('Loaded json models')\n",
    "    \n",
    "    \n",
    "def load_data():\n",
    "    connection = con.get_connection('image_profile')\n",
    "    imgur = X_data(connection,'imgur_convolution')    \n",
    "    connection.close()\n",
    "    imgur.df.loc[imgur.df['label']=='imgur' ,'y'] = 0\n",
    "\n",
    "\n",
    "    connection = con.get_connection('image_profile')\n",
    "    unsplash = X_data(connection,'unsplash_convolution')    \n",
    "    connection.close()\n",
    "    unsplash.df.loc[unsplash.df['label']=='unsplash' ,'y'] = 1\n",
    "\n",
    "    X = np.concatenate((imgur.df.x.values, unsplash.df.x.values), axis=0)\n",
    "    y = np.concatenate((imgur.df.y.values, unsplash.df.y.values), axis=0)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def test_split(X,y):\n",
    "    # This fixes the 'setting an array index with a sequence' ValueError\n",
    "    arr = np.zeros(len(X),dtype=object)\n",
    "    for i in range(len(X)): \n",
    "        arr[i]=X[i]\n",
    "\n",
    "    arr = np.array(arr.tolist())\n",
    "    X = arr.reshape(len(X),len(X[0]))\n",
    "\n",
    "    arr = np.zeros(len(y),dtype=object)\n",
    "    for i in range(len(y)): \n",
    "        arr[i]=y[i]\n",
    "\n",
    "    arr = np.array(arr.tolist())\n",
    "    y = arr.reshape(len(y),1)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def generate_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print('Training size:',len(X_train))\n",
    "    print('Testing size:',len(X_test))\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()  \n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(0.95)  \n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipeline = Pipeline([('scaler', sc), ('pca', pca),('rforest',rf)])\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    param_grid = {\n",
    "        'rforest__bootstrap': [True],\n",
    "        'rforest__max_depth': [80, 90, 100, 110],\n",
    "        'rforest__max_features': [2],\n",
    "        'rforest__min_samples_leaf': [3],\n",
    "        'rforest__min_samples_split': [8, ],\n",
    "        'rforest__n_estimators': [100, 200, 300]\n",
    "    }\n",
    "    grid_search = GridSearchCV(pipeline, param_grid = param_grid,cv = 2, n_jobs = 1, verbose = 2)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_search.best_params_\n",
    "\n",
    "    # best_params__ = {'bootstrap': True,\n",
    "    #                  'max_depth': 90,\n",
    "    #                  'max_features': 2,\n",
    "    #                  'min_samples_leaf': 3,\n",
    "    #                  'min_samples_split': 8,\n",
    "    #                  'n_estimators': 300}\n",
    "\n",
    "    model = grid_search.best_estimator_\n",
    "    y_pred = model.predict(X_test)\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def store_model(model,filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(bgr_quality_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return True\n",
    "\n",
    "def load_model(file):\n",
    "    # Load data (deserialize)\n",
    "    with open(file, 'rb') as handle:\n",
    "        unserialized_data = pickle.load(handle)\n",
    "    return unserialized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded json models\n",
      "Loaded json models\n"
     ]
    }
   ],
   "source": [
    "X,y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 487489\n",
      "Testing size: 240107\n",
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV] rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=100, total= 2.0min\n",
      "[CV] rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=100, total= 2.0min\n",
      "[CV] rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=200, total= 3.8min\n",
      "[CV] rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=200, total= 3.9min\n",
      "[CV] rforest__bootstrap=True, rforest__max_depth=80, rforest__max_features=2, rforest__min_samples_leaf=3, rforest__min_samples_split=8, rforest__n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py:250: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_model(model,'../models/quality_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
